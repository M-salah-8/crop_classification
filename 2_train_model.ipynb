{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from funcs import plot_class_profiles, plot_class_profiles_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepair Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training area e.g. (data and image were made using QGIS)\n",
    "# display(Image.open(os.path.join('examples', 'train_area.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['beans', 'potato', 'wheat', 'others']\n",
    "class_colors = ['purple', 'green', 'goldenrod', 'brown']\n",
    "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12','ndvi']   # add NDVI band (recommended in the literatures)\n",
    "data_dr = os.path.join('data', 's2') # where data is saved\n",
    "stacked_tif_dr = os.path.join('data', 'stacked_bands.tif') # where stacked image is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling the tif file\n",
    "src = rasterio.open(stacked_tif_dr)\n",
    "tif_files = sorted(glob.glob(data_dr+'/*.tif'))\n",
    "train_pts = gpd.read_file(os.path.join('data','points','train_pts.shp'))\n",
    "train_pts = train_pts[['type','xcoord','ycoord','geometry']].sort_values(by=['type'])\t# mention xcoord, ycoord in docs\n",
    "coords = [(x,y) for x, y in zip(train_pts.xcoord, train_pts.ycoord)]\n",
    "train_pts['Raster Value'] = [x for x in src.sample(coords)]\t\t# mention same crs in docs\n",
    "\n",
    "# put every tif band in a column\n",
    "bands_names = []\n",
    "for tif_file in tif_files:\n",
    "  tif_name = os.path.basename(tif_file).split('.')[0]\n",
    "  for band in bands:\n",
    "    bands_names.append(f'{band}_{tif_name}')\n",
    "\n",
    "train_pts = pd.concat([train_pts, pd.DataFrame(train_pts['Raster Value'].tolist(), index=train_pts.index, columns=bands_names)], axis=1)\n",
    "train_pts = train_pts.drop(['xcoord','ycoord','geometry','Raster Value'], axis=1)\n",
    "train_pts.to_csv(os.path.join('data','train_pts.csv')) # save our training dataset to CSV\n",
    "train_pts.head() # visualize the first rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories data by type to split the training / validation data efficiently\n",
    "class_dfs = [train_pts[train_pts['type'] == 1].iloc[:,:],\n",
    "train_pts[train_pts['type'] == 2].iloc[:,:],\n",
    "train_pts[train_pts['type'] == 3].iloc[:,:],\n",
    "train_pts[train_pts['type'] == 5].iloc[:,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Class profiles over our dataset\n",
    "plot_class_profiles(class_dfs, class_colors, class_names, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Class profiles over our dataset (mean)\n",
    "plot_class_profiles_mean(train_pts, class_colors, class_names, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt the data into training and validation\n",
    "values_arrays = []\n",
    "for class_df in class_dfs:\n",
    "  # Split training dataset to labels (y) and input features (x)\n",
    "  y = class_df['type'].values\n",
    "  x = class_df[[b for b in bands_names if \"B\" or 'ndvi' in b]].values # Only Sentinel-2 data\n",
    "  # del(class_df, coords)\n",
    "  values_arrays.append(train_test_split(x, y, test_size=0.30, shuffle = True,random_state=10)) # [x_train, x_val, y_train, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros([0,len(bands_names)])\n",
    "x_val = np.zeros([0,len(bands_names)])\n",
    "y_train = np.zeros([0])\n",
    "y_val = np.zeros([0])\n",
    "for values_array in values_arrays:\n",
    "  x_train = np.append(x_train, values_array[0], axis= 0)\n",
    "  x_val = np.append(x_val, values_array[1], axis= 0)\n",
    "  y_train = np.append(y_train, values_array[2])\n",
    "  y_val = np.append(y_val, values_array[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The trainng data sizes are: Sentinel-2 x_train{x_train.shape}, x_val{x_val.shape},y_train {y_train.shape},y_val{y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "rf = RandomForestClassifier(n_estimators=300, oob_score=True)\n",
    "rf= rf.fit(x_train, y_train)# Fit the model to the training dataset\n",
    "# The 00B score of the training dataset obtained using an out-of-bag estimate.\n",
    "print('Our 00B prediction of accuracy for s2 stack is: {oob}s'.format(oob=rf.oob_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction on the validation dataste\n",
    "y_pred = rf.predict(x_val)\n",
    "print('Sentinel-2')\n",
    "print(classification_report(y_val, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from tabulate import tabulate\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Prepare table data\n",
    "table_data = []\n",
    "# Table header\n",
    "table_data.append([\"True\"] + list(class_names))\n",
    "\n",
    "# Table rows\n",
    "for i, name in enumerate(class_names):\n",
    "    table_data.append([name] + list(cm[i]))\n",
    "\n",
    "# Print the table using tabulate library\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "with open(os.path.join('data', 'trained_model.pkl'), \"wb\") as f:\n",
    "\tpickle.dump(rf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
